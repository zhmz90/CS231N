# Lecture 10: Recurrent Neural Networks

### (Vanilla) Recurrent Neural Network
  - min-char-rnn.py
  - how to searching for interpretable cells?
  
### Image Captions
  - CNN + RNN
  
### LSTM
  - 3 gates: i,f,o
  - get information from input: g
  - cell state, hidden state: c,h
  - Residual Module
    - H(x) = F(x) + x

### Understanding gradient flow dynamics
  - gradient explode: gradient clip
  - gradient vanish
    - LSTM 
      - vanishing is controlled with additive interactions
      - ??? why? because of its residual module?
  


